{
  "agent": "agent-a-paper-fetcher",
  "timestamp": "2025-11-25T09:04:23.290444",
  "status": "completed",
  "data": {
    "papers": [
      {
        "id": "2511.19436v1",
        "title": "VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic Self-Reflection",
        "authors": [
          "Qiang Wang",
          "Xinyuan Gao",
          "SongLin Dong",
          "Jizhou Han",
          "Jiangyang Li"
        ],
        "abstract": "We present VDC-Agent, a self-evolving framework for Video Detailed Captioning that requires neither human annotations nor larger teacher models. The agent forms a closed loop of caption generation, principle-guided scoring (score and textual suggestions), and prompt refinement. When caption quality regresses, a self-reflection path leverages the previous chain-of-thought to amend the update. Running this process on unlabeled videos produces trajectories of (caption, score) pairs. We convert the ...",
        "published": "2025-11-24T18:59:56Z",
        "updated": "2025-11-24T18:59:56Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19436v1",
        "abs_url": "https://arxiv.org/abs/2511.19436v1",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG",
          "cs.MM"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2511.19434v1",
        "title": "Breaking the Likelihood-Quality Trade-off in Diffusion Models by Merging Pretrained Experts",
        "authors": [
          "Yasin Esfandiari",
          "Stefan Bauer",
          "Sebastian U. Stich",
          "Andrea Dittadi"
        ],
        "abstract": "Diffusion models for image generation often exhibit a trade-off between perceptual sample quality and data likelihood: training objectives emphasizing high-noise denoising steps yield realistic images but poor likelihoods, whereas likelihood-oriented training overweights low-noise steps and harms visual fidelity. We introduce a simple plug-and-play sampling method that combines two pretrained diffusion experts by switching between them along the denoising trajectory. Specifically, we apply an im...",
        "published": "2025-11-24T18:59:53Z",
        "updated": "2025-11-24T18:59:53Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19434v1",
        "abs_url": "https://arxiv.org/abs/2511.19434v1",
        "categories": [
          "cs.CV",
          "cs.LG",
          "stat.ML"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2511.19433v1",
        "title": "Mixture of Horizons in Action Chunking",
        "authors": [
          "Dong Jing",
          "Gang Wang",
          "Jiaqi Liu",
          "Weiliang Tang",
          "Zelong Sun"
        ],
        "abstract": "Vision-language-action (VLA) models have shown remarkable capabilities in robotic manipulation, but their performance is sensitive to the $\\textbf{action chunk length}$ used during training, termed $\\textbf{horizon}$. Our empirical study reveals an inherent trade-off: longer horizons provide stronger global foresight but degrade fine-grained accuracy, while shorter ones sharpen local control yet struggle on long-term tasks, implying fixed choice of single horizons being suboptimal. To mitigate t...",
        "published": "2025-11-24T18:59:51Z",
        "updated": "2025-11-24T18:59:51Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19433v1",
        "abs_url": "https://arxiv.org/abs/2511.19433v1",
        "categories": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ],
        "primary_category": "cs.RO"
      },
      {
        "id": "2511.19428v1",
        "title": "Flow Map Distillation Without Data",
        "authors": [
          "Shangyuan Tong",
          "Nanye Ma",
          "Saining Xie",
          "Tommi Jaakkola"
        ],
        "abstract": "State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, a procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces a fundamental risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or even misaligned representation of the teacher's full generative capabilities. This leads us to question whether this...",
        "published": "2025-11-24T18:58:55Z",
        "updated": "2025-11-24T18:58:55Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19428v1",
        "abs_url": "https://arxiv.org/abs/2511.19428v1",
        "categories": [
          "cs.LG",
          "cs.CV"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.19427v1",
        "title": "Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt Engineering",
        "authors": [
          "Jayanaka L. Dantanarayana",
          "Savini Kashmira",
          "Thakee Nathees",
          "Zichen Zhang",
          "Krisztian Flautner"
        ],
        "abstract": "AI-Integrated programming is emerging as a foundational paradigm for building intelligent systems with large language models (LLMs). Recent approaches such as Meaning Typed Programming (MTP) automate prompt generation by leveraging the semantics already present in code. However, many real-world applications depend on contextual cues, developer intent, and domain-specific reasoning that extend beyond what static code semantics alone can express. To address this limitation, we introduce Semantic E...",
        "published": "2025-11-24T18:58:22Z",
        "updated": "2025-11-24T18:58:22Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19427v1",
        "abs_url": "https://arxiv.org/abs/2511.19427v1",
        "categories": [
          "cs.SE",
          "cs.AI"
        ],
        "primary_category": "cs.SE"
      },
      {
        "id": "2511.19423v1",
        "title": "Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design",
        "authors": [
          "Bruno Jacob",
          "Khushbu Agarwal",
          "Marcel Baer",
          "Peter Rice",
          "Simone Raugei"
        ],
        "abstract": "We present Genie-CAT, a tool-augmented large-language-model (LLM) system designed to accelerate scientific hypothesis generation in protein design. Using metalloproteins (e.g., ferredoxins) as a case study, Genie-CAT integrates four capabilities -- literature-grounded reasoning through retrieval-augmented generation (RAG), structural parsing of Protein Data Bank files, electrostatic potential calculations, and machine-learning prediction of redox properties -- into a unified agentic workflow. By...",
        "published": "2025-11-24T18:57:07Z",
        "updated": "2025-11-24T18:57:07Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19423v1",
        "abs_url": "https://arxiv.org/abs/2511.19423v1",
        "categories": [
          "q-bio.QM",
          "cs.AI"
        ],
        "primary_category": "q-bio.QM"
      },
      {
        "id": "2511.19422v1",
        "title": "SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning",
        "authors": [
          "David Jiahao Fu",
          "Aryan Gupta",
          "Aaron Councilman",
          "David Grove",
          "Yu-Xiong Wang"
        ],
        "abstract": "Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generati...",
        "published": "2025-11-24T18:56:47Z",
        "updated": "2025-11-24T18:56:47Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19422v1",
        "abs_url": "https://arxiv.org/abs/2511.19422v1",
        "categories": [
          "cs.SE",
          "cs.AI",
          "cs.PL"
        ],
        "primary_category": "cs.SE"
      },
      {
        "id": "2511.19418v1",
        "title": "Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens",
        "authors": [
          "Yiming Qin",
          "Bomin Wei",
          "Jiaxin Ge",
          "Konstantinos Kallidromitis",
          "Stephanie Fu"
        ],
        "abstract": "Vision-Language Models (VLMs) excel at reasoning in linguistic space but struggle with perceptual understanding that requires dense visual perception, e.g., spatial reasoning and geometric awareness. This limitation stems from the fact that current VLMs have limited mechanisms to capture dense visual information across spatial dimensions. We introduce Chain-of-Visual-Thought (COVT), a framework that enables VLMs to reason not only in words but also through continuous visual tokens-compact latent...",
        "published": "2025-11-24T18:55:19Z",
        "updated": "2025-11-24T18:55:19Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19418v1",
        "abs_url": "https://arxiv.org/abs/2511.19418v1",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2511.19417v1",
        "title": "Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration",
        "authors": [
          "James Y. Huang",
          "Sheng Zhang",
          "Qianchu Liu",
          "Guanghui Qin",
          "Tinghui Zhu"
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framew...",
        "published": "2025-11-24T18:55:16Z",
        "updated": "2025-11-24T18:55:16Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19417v1",
        "abs_url": "https://arxiv.org/abs/2511.19417v1",
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2511.19413v1",
        "title": "UniGame: Turning a Unified Multimodal Model Into Its Own Adversary",
        "authors": [
          "Zhaolong Su",
          "Wang Lu",
          "Hao Chen",
          "Sharon Li",
          "Jindong Wang"
        ],
        "abstract": "Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame,...",
        "published": "2025-11-24T18:50:01Z",
        "updated": "2025-11-24T18:50:01Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19413v1",
        "abs_url": "https://arxiv.org/abs/2511.19413v1",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CV"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.19405v1",
        "title": "Learning Robust Social Strategies with Large Language Models",
        "authors": [
          "Dereck Piche",
          "Mohammed Muqeeth",
          "Milad Aghajohari",
          "Juan Duque",
          "Michael Noukhovitch"
        ],
        "abstract": "As agentic AI becomes more widespread, agents with distinct and possibly conflicting goals will interact in complex ways. These multi-agent interactions pose a fundamental challenge, particularly in social dilemmas, where agents' individual incentives can undermine collective welfare. While reinforcement learning (RL) has been effective for aligning large language models (LLMs) in the single-agent regime, prior small-network results suggest that standard RL in multi-agent settings often converge...",
        "published": "2025-11-24T18:43:46Z",
        "updated": "2025-11-24T18:43:46Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19405v1",
        "abs_url": "https://arxiv.org/abs/2511.19405v1",
        "categories": [
          "cs.LG"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.19404v1",
        "title": "Nonparametric Instrumental Variable Regression with Observed Covariates",
        "authors": [
          "Zikai Shen",
          "Zonghao Chen",
          "Dimitri Meunier",
          "Ingo Steinwart",
          "Arthur Gretton"
        ],
        "abstract": "We study the problem of nonparametric instrumental variable regression with observed covariates, which we refer to as NPIV-O. Compared with standard nonparametric instrumental variable regression (NPIV), the additional observed covariates facilitate causal identification and enables heterogeneous causal effect estimation. However, the presence of observed covariates introduces two challenges for its theoretical analysis. First, it induces a partial identity structure, which renders previous NPIV...",
        "published": "2025-11-24T18:42:49Z",
        "updated": "2025-11-24T18:42:49Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19404v1",
        "abs_url": "https://arxiv.org/abs/2511.19404v1",
        "categories": [
          "stat.ML",
          "cs.LG",
          "math.ST"
        ],
        "primary_category": "stat.ML"
      },
      {
        "id": "2511.19401v1",
        "title": "In-Video Instructions: Visual Signals as Generative Control",
        "authors": [
          "Gongfan Fang",
          "Xinyin Ma",
          "Xinchao Wang"
        ],
        "abstract": "Large-scale video generative models have recently demonstrated strong visual capabilities, enabling the prediction of future frames that adhere to the logical and physical cues in the current observation. In this work, we investigate whether such capabilities can be harnessed for controllable image-to-video generation by interpreting visual signals embedded within the frames as instructions, a paradigm we term In-Video Instruction. In contrast to prompt-based control, which provides textual desc...",
        "published": "2025-11-24T18:38:45Z",
        "updated": "2025-11-24T18:38:45Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19401v1",
        "abs_url": "https://arxiv.org/abs/2511.19401v1",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2511.19399v1",
        "title": "DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research",
        "authors": [
          "Rulin Shao",
          "Akari Asai",
          "Shannon Zejiang Shen",
          "Hamish Ivison",
          "Varsha Kishore"
        ],
        "abstract": "Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to in...",
        "published": "2025-11-24T18:35:54Z",
        "updated": "2025-11-24T18:35:54Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19399v1",
        "abs_url": "https://arxiv.org/abs/2511.19399v1",
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2511.19398v1",
        "title": "PTF Testing Lower Bounds for Non-Gaussian Component Analysis",
        "authors": [
          "Ilias Diakonikolas",
          "Daniel M. Kane",
          "Sihan Liu",
          "Thanasis Pittas"
        ],
        "abstract": "This work studies information-computation gaps for statistical problems. A common approach for providing evidence of such gaps is to show sample complexity lower bounds (that are stronger than the information-theoretic optimum) against natural models of computation. A popular such model in the literature is the family of low-degree polynomial tests. While these tests are defined in such a way that make them easy to analyze, the class of algorithms that they rule out is somewhat restricted. An im...",
        "published": "2025-11-24T18:35:29Z",
        "updated": "2025-11-24T18:35:29Z",
        "pdf_url": "https://arxiv.org/pdf/2511.19398v1",
        "abs_url": "https://arxiv.org/abs/2511.19398v1",
        "categories": [
          "cs.DS",
          "cs.IT",
          "cs.LG",
          "math.ST",
          "stat.ML"
        ],
        "primary_category": "cs.DS"
      }
    ],
    "count": 15,
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.CL"
    ],
    "fetch_date": "2025-11-25"
  },
  "metadata": {
    "source": "arXiv API",
    "query": "cat:cs.AI OR cat:cs.LG OR cat:cs.CL",
    "deduplication": {
      "total_fetched": 15,
      "new_papers": 15,
      "duplicates_filtered": 0,
      "last_fetch": "2025-11-24T09:03:59.666014"
    }
  },
  "costs": {
    "execution_time": 0.5326287746429443,
    "execution_minutes": 0.008877146244049072,
    "github_actions": 7.101716995239257e-05,
    "openai": {
      "input": 0,
      "output": 0,
      "total": 0
    },
    "total": 7.101716995239257e-05,
    "token_usage": {}
  }
}