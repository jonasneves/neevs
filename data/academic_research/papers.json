{
  "agent": "agent-a-paper-fetcher",
  "timestamp": "2025-12-10T09:04:57.135514",
  "status": "completed",
  "data": {
    "papers": [
      {
        "id": "2512.08931v1",
        "title": "Astra: General Interactive World Model with Autoregressive Denoising",
        "authors": [
          "Yixuan Zhu",
          "Jiaqi Feng",
          "Wenzhao Zheng",
          "Yuan Gao",
          "Xin Tao"
        ],
        "abstract": "Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, rob...",
        "published": "2025-12-09T18:59:57Z",
        "updated": "2025-12-09T18:59:57Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08931v1",
        "abs_url": "https://arxiv.org/abs/2512.08931v1",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2512.08923v1",
        "title": "Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs",
        "authors": [
          "Angela van Sprang",
          "Laurens Samson",
          "Ana Lucic",
          "Erman Acar",
          "Sennay Ghebreab"
        ],
        "abstract": "We introduce two new benchmarks REST and REST+(Render-Equivalence Stress Tests) to enable systematic evaluation of cross-modal inconsistency in multimodal large language models (MLLMs). MLLMs are trained to represent vision and language in the same embedding space, yet they cannot perform the same tasks in both modalities. Our benchmarks contain samples with the same semantic information in three modalities (image, text, mixed) and we show that state-of-the-art MLLMs cannot consistently reason o...",
        "published": "2025-12-09T18:57:07Z",
        "updated": "2025-12-09T18:57:07Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08923v1",
        "abs_url": "https://arxiv.org/abs/2512.08923v1",
        "categories": [
          "cs.AI"
        ],
        "primary_category": "cs.AI"
      },
      {
        "id": "2512.08920v1",
        "title": "OSMO: Open-Source Tactile Glove for Human-to-Robot Skill Transfer",
        "authors": [
          "Jessica Yin",
          "Haozhi Qi",
          "Youngsun Wi",
          "Sayantan Kundu",
          "Mike Lambeta"
        ],
        "abstract": "Human video demonstrations provide abundant training data for learning robot policies, but video alone cannot capture the rich contact signals critical for mastering manipulation. We introduce OSMO, an open-source wearable tactile glove designed for human-to-robot skill transfer. The glove features 12 three-axis tactile sensors across the fingertips and palm and is designed to be compatible with state-of-the-art hand-tracking methods for in-the-wild data collection. We demonstrate that a robot p...",
        "published": "2025-12-09T18:56:30Z",
        "updated": "2025-12-09T18:56:30Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08920v1",
        "abs_url": "https://arxiv.org/abs/2512.08920v1",
        "categories": [
          "cs.RO",
          "cs.LG"
        ],
        "primary_category": "cs.RO"
      },
      {
        "id": "2512.08914v1",
        "title": "SAQ: Stabilizer-Aware Quantum Error Correction Decoder",
        "authors": [
          "David Zenati",
          "Eliya Nachmani"
        ],
        "abstract": "Quantum Error Correction (QEC) decoding faces a fundamental accuracy-efficiency tradeoff. Classical methods like Minimum Weight Perfect Matching (MWPM) exhibit variable performance across noise models and suffer from polynomial complexity, while tensor network decoders achieve high accuracy but at prohibitively high computational cost. Recent neural decoders reduce complexity but lack the accuracy needed to compete with computationally expensive classical methods. We introduce SAQ-Decoder, a uni...",
        "published": "2025-12-09T18:51:35Z",
        "updated": "2025-12-09T18:51:35Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08914v1",
        "abs_url": "https://arxiv.org/abs/2512.08914v1",
        "categories": [
          "quant-ph",
          "cs.AI"
        ],
        "primary_category": "quant-ph"
      },
      {
        "id": "2512.08896v1",
        "title": "Open Polymer Challenge: Post-Competition Report",
        "authors": [
          "Gang Liu",
          "Sobin Alosious",
          "Subhamoy Mahajan",
          "Eric Inae",
          "Yihan Zhu"
        ],
        "abstract": "Machine learning (ML) offers a powerful path toward discovering sustainable polymer materials, but progress has been limited by the lack of large, high-quality, and openly accessible polymer datasets. The Open Polymer Challenge (OPC) addresses this gap by releasing the first community-developed benchmark for polymer informatics, featuring a dataset with 10K polymers and 5 properties: thermal conductivity, radius of gyration, density, fractional free volume, and glass transition temperature. The ...",
        "published": "2025-12-09T18:38:15Z",
        "updated": "2025-12-09T18:38:15Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08896v1",
        "abs_url": "https://arxiv.org/abs/2512.08896v1",
        "categories": [
          "cs.LG"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.08895v1",
        "title": "Unsupervised Learning of Density Estimates with Topological Optimization",
        "authors": [
          "Suina Tanweer",
          "Firas A. Khasawneh"
        ],
        "abstract": "Kernel density estimation is a key component of a wide variety of algorithms in machine learning, Bayesian inference, stochastic dynamics and signal processing. However, the unsupervised density estimation technique requires tuning a crucial hyperparameter: the kernel bandwidth. The choice of bandwidth is critical as it controls the bias-variance trade-off by over- or under-smoothing the topological features. Topological data analysis provides methods to mathematically quantify topological chara...",
        "published": "2025-12-09T18:35:51Z",
        "updated": "2025-12-09T18:35:51Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08895v1",
        "abs_url": "https://arxiv.org/abs/2512.08895v1",
        "categories": [
          "cs.LG",
          "stat.ML"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.08894v1",
        "title": "Revisiting the Scaling Properties of Downstream Metrics in Large Language Model Training",
        "authors": [
          "Jakub Krajewski",
          "Amitis Shidani",
          "Dan Busbridge",
          "Sam Wiseman",
          "Jason Ramapuram"
        ],
        "abstract": "While scaling laws for Large Language Models (LLMs) traditionally focus on proxy metrics like pretraining loss, predicting downstream task performance has been considered unreliable. This paper challenges that view by proposing a direct framework to model the scaling of benchmark performance from the training budget. We find that for a fixed token-to-parameter ratio, a simple power law can accurately describe the scaling behavior of log accuracy on multiple popular downstream tasks. Our results ...",
        "published": "2025-12-09T18:33:48Z",
        "updated": "2025-12-09T18:33:48Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08894v1",
        "abs_url": "https://arxiv.org/abs/2512.08894v1",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.08892v1",
        "title": "Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders",
        "authors": [
          "Guangzhi Xiong",
          "Zhenghao He",
          "Bohan Liu",
          "Sanchit Sinha",
          "Aidong Zhang"
        ],
        "abstract": "Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approach...",
        "published": "2025-12-09T18:33:22Z",
        "updated": "2025-12-09T18:33:22Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08892v1",
        "abs_url": "https://arxiv.org/abs/2512.08892v1",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2512.08889v1",
        "title": "No Labels, No Problem: Training Visual Reasoners with Multimodal Verifiers",
        "authors": [
          "Damiano Marsili",
          "Georgia Gkioxari"
        ],
        "abstract": "Visual reasoning is challenging, requiring both precise object grounding and understanding complex spatial relationships. Existing methods fall into two camps: language-only chain-of-thought approaches, which demand large-scale (image, query, answer) supervision, and program-synthesis approaches which use pre-trained models and avoid training, but suffer from flawed logic and erroneous grounding. We propose an annotation-free training framework that improves both reasoning and grounding. Our fra...",
        "published": "2025-12-09T18:30:23Z",
        "updated": "2025-12-09T18:30:23Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08889v1",
        "abs_url": "https://arxiv.org/abs/2512.08889v1",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2512.08885v1",
        "title": "Explainable Anomaly Detection for Industrial IoT Data Streams",
        "authors": [
          "Ana Rita Paup\u00e9rio",
          "Diogo Risca",
          "Afonso Louren\u00e7o",
          "Goreti Marreiros",
          "Ricardo Martins"
        ],
        "abstract": "Industrial maintenance is being transformed by the Internet of Things and edge computing, generating continuous data streams that demand real-time, adaptive decision-making under limited computational resources. While data stream mining (DSM) addresses this challenge, most methods assume fully supervised settings, yet in practice, ground-truth labels are often delayed or unavailable. This paper presents a collaborative DSM framework that integrates unsupervised anomaly detection with interactive...",
        "published": "2025-12-09T18:20:35Z",
        "updated": "2025-12-09T18:20:35Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08885v1",
        "abs_url": "https://arxiv.org/abs/2512.08885v1",
        "categories": [
          "cs.LG"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.08882v1",
        "title": "Decentralized Trust for Space AI: Blockchain-Based Federated Learning Across Multi-Vendor LEO Satellite Networks",
        "authors": [
          "Mohamed Elmahallawy",
          "Asma Jodeiri Akbarfam"
        ],
        "abstract": "The rise of space AI is reshaping government and industry through applications such as disaster detection, border surveillance, and climate monitoring, powered by massive data from commercial and governmental low Earth orbit (LEO) satellites. Federated satellite learning (FSL) enables joint model training without sharing raw data, but suffers from slow convergence due to intermittent connectivity and introduces critical trust challenges--where biased or falsified updates can arise across satelli...",
        "published": "2025-12-09T18:16:34Z",
        "updated": "2025-12-09T18:16:34Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08882v1",
        "abs_url": "https://arxiv.org/abs/2512.08882v1",
        "categories": [
          "cs.CR",
          "cs.LG"
        ],
        "primary_category": "cs.CR"
      },
      {
        "id": "2512.08879v1",
        "title": "DAO-GP Drift Aware Online Non-Linear Regression Gaussian-Process",
        "authors": [
          "Mohammad Abu-Shaira",
          "Ajita Rattani",
          "Weishi Shi"
        ],
        "abstract": "Real-world datasets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. Gaussian Process (GP) models offer powerful non-parametric...",
        "published": "2025-12-09T18:12:38Z",
        "updated": "2025-12-09T18:12:38Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08879v1",
        "abs_url": "https://arxiv.org/abs/2512.08879v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.08875v1",
        "title": "When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation",
        "authors": [
          "Joshua Ward",
          "Bochao Gu",
          "Chi-Hua Wang",
          "Guang Cheng"
        ],
        "abstract": "Large Language Models (LLMs) have recently demonstrated remarkable performance in generating high-quality tabular synthetic data. In practice, two primary approaches have emerged for adapting LLMs to tabular data generation: (i) fine-tuning smaller models directly on tabular datasets, and (ii) prompting larger models with examples provided in context. In this work, we show that popular implementations from both regimes exhibit a tendency to compromise privacy by reproducing memorized patterns of...",
        "published": "2025-12-09T18:06:31Z",
        "updated": "2025-12-09T18:06:31Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08875v1",
        "abs_url": "https://arxiv.org/abs/2512.08875v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.08873v1",
        "title": "Siamese-Driven Optimization for Low-Resolution Image Latent Embedding in Image Captioning",
        "authors": [
          "Jing Jie Tan",
          "Anissa Mokraoui",
          "Ban-Hoe Kwan",
          "Danny Wee-Kiat Ng",
          "Yan-Chai Hum"
        ],
        "abstract": "Image captioning is essential in many fields including assisting visually impaired individuals, improving content management systems, and enhancing human-computer interaction. However, a recent challenge in this domain is dealing with low-resolution image (LRI). While performance can be improved by using larger models like transformers for encoding, these models are typically heavyweight, demanding significant computational resources and memory, leading to challenges in retraining. To address th...",
        "published": "2025-12-09T18:05:59Z",
        "updated": "2025-12-09T18:05:59Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08873v1",
        "abs_url": "https://arxiv.org/abs/2512.08873v1",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.HC"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2512.08870v1",
        "title": "Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents",
        "authors": [
          "Xiang Chen",
          "Yuling Shi",
          "Qizhen Lan",
          "Yuchao Qiu",
          "Xiaodong Gu"
        ],
        "abstract": "LLM agents are widely deployed in complex interactive tasks, yet privacy constraints often preclude centralized optimization and co-evolution across dynamic environments. While Federated Learning (FL) has proven effective on static datasets, its extension to the open-ended self-evolution of agents remains underexplored. Directly applying standard FL is challenging: heterogeneous tasks and sparse, trajectory-level rewards introduce severe gradient conflicts, destabilizing the global optimization ...",
        "published": "2025-12-09T18:04:41Z",
        "updated": "2025-12-09T18:04:41Z",
        "pdf_url": "https://arxiv.org/pdf/2512.08870v1",
        "abs_url": "https://arxiv.org/abs/2512.08870v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "primary_category": "cs.LG"
      }
    ],
    "count": 15,
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.CL"
    ],
    "fetch_date": "2025-12-10"
  },
  "metadata": {
    "source": "arXiv API",
    "query": "cat:cs.AI OR cat:cs.LG OR cat:cs.CL",
    "deduplication": {
      "total_fetched": 15,
      "new_papers": 15,
      "duplicates_filtered": 0,
      "last_fetch": "2025-12-09T09:04:56.850960"
    }
  },
  "costs": {
    "execution_time": 1.3811733722686768,
    "execution_minutes": 0.023019556204477945,
    "github_actions": 0.00018415644963582357,
    "openai": {
      "input": 0,
      "output": 0,
      "total": 0
    },
    "total": 0.00018415644963582357,
    "token_usage": {}
  }
}