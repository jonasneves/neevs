{
  "agent": "agent-a-paper-fetcher",
  "timestamp": "2025-11-19T09:03:14.922619",
  "status": "completed",
  "data": {
    "papers": [
      {
        "id": "2511.14761v1",
        "title": "ARC Is a Vision Problem!",
        "authors": [
          "Keya Hu",
          "Ali Cy",
          "Linlu Qiu",
          "Xiaoman Delores Ding",
          "Runqian Wang"
        ],
        "abstract": "The Abstraction and Reasoning Corpus (ARC) is designed to promote research on abstract reasoning, a fundamental aspect of human intelligence. Common approaches to ARC treat it as a language-oriented problem, addressed by large language models (LLMs) or recurrent reasoning models. However, although the puzzle-like tasks in ARC are inherently visual, existing research has rarely approached the problem from a vision-centric perspective. In this work, we formulate ARC within a vision paradigm, frami...",
        "published": "2025-11-18T18:59:49Z",
        "updated": "2025-11-18T18:59:49Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14761v1",
        "abs_url": "https://arxiv.org/abs/2511.14761v1",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2511.14759v1",
        "title": "$\u03c0^{*}_{0.6}$: a VLA That Learns From Experience",
        "authors": [
          "Ali Amin",
          "Raichelle Aniceto",
          "Ashwin Balakrishna",
          "Kevin Black",
          "Ken Conley"
        ],
        "abstract": "We study how vision-language-action (VLA) models can improve through real-world deployments via reinforcement learning (RL). We present a general-purpose method, RL with Experience and Corrections via Advantage-conditioned Policies (RECAP), that provides for RL training of VLAs via advantage conditioning. Our method incorporates heterogeneous data into the self-improvement process, including demonstrations, data from on-policy collection, and expert teleoperated interventions provided during aut...",
        "published": "2025-11-18T18:58:55Z",
        "updated": "2025-11-18T18:58:55Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14759v1",
        "abs_url": "https://arxiv.org/abs/2511.14759v1",
        "categories": [
          "cs.LG",
          "cs.RO"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.14755v1",
        "title": "Robust Verification of Controllers under State Uncertainty via Hamilton-Jacobi Reachability Analysis",
        "authors": [
          "Albert Lin",
          "Alessandro Pinto",
          "Somil Bansal"
        ],
        "abstract": "As perception-based controllers for autonomous systems become increasingly popular in the real world, it is important that we can formally verify their safety and performance despite perceptual uncertainty. Unfortunately, the verification of such systems remains challenging, largely due to the complexity of the controllers, which are often nonlinear, nonconvex, learning-based, and/or black-box. Prior works propose verification algorithms that are based on approximate reachability methods, but th...",
        "published": "2025-11-18T18:55:20Z",
        "updated": "2025-11-18T18:55:20Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14755v1",
        "abs_url": "https://arxiv.org/abs/2511.14755v1",
        "categories": [
          "cs.RO",
          "cs.LG",
          "eess.SY"
        ],
        "primary_category": "cs.RO"
      },
      {
        "id": "2511.14753v1",
        "title": "SparseST: Exploiting Data Sparsity in Spatiotemporal Modeling and Prediction",
        "authors": [
          "Junfeng Wu",
          "Hadjer Benmeziane",
          "Kaoutar El Maghraoui",
          "Liu Liu",
          "Yinan Wang"
        ],
        "abstract": "Spatiotemporal data mining (STDM) has a wide range of applications in various complex physical systems (CPS), i.e., transportation, manufacturing, healthcare, etc. Among all the proposed methods, the Convolutional Long Short-Term Memory (ConvLSTM) has proved to be generalizable and extendable in different applications and has multiple variants achieving state-of-the-art performance in various STDM applications. However, ConvLSTM and its variants are computationally expensive, which makes them in...",
        "published": "2025-11-18T18:53:37Z",
        "updated": "2025-11-18T18:53:37Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14753v1",
        "abs_url": "https://arxiv.org/abs/2511.14753v1",
        "categories": [
          "cs.LG",
          "cs.CE"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.14745v1",
        "title": "Look-Ahead Reasoning on Learning Platforms",
        "authors": [
          "Haiqing Zhu",
          "Tijana Zrnic",
          "Celestine Mendler-D\u00fcnner"
        ],
        "abstract": "On many learning platforms, the optimization criteria guiding model training reflect the priorities of the designer rather than those of the individuals they affect. Consequently, users may act strategically to obtain more favorable outcomes, effectively contesting the platform's predictions. While past work has studied strategic user behavior on learning platforms, the focus has largely been on strategic responses to a deployed model, without considering the behavior of other users. In contrast...",
        "published": "2025-11-18T18:45:32Z",
        "updated": "2025-11-18T18:45:32Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14745v1",
        "abs_url": "https://arxiv.org/abs/2511.14745v1",
        "categories": [
          "cs.LG",
          "cs.GT",
          "stat.ML"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.14744v1",
        "title": "Measuring AI Progress in Drug Discovery: A Reproducible Leaderboard for the Tox21 Challenge",
        "authors": [
          "Antonia Ebner",
          "Christoph Bartmann",
          "Sonja Topf",
          "Sohvi Luukkonen",
          "Johannes Schimunek"
        ],
        "abstract": "Deep learning's rise since the early 2010s has transformed fields like computer vision and natural language processing and strongly influenced biomedical research. For drug discovery specifically, a key inflection - akin to vision's \"ImageNet moment\" - arrived in 2015, when deep neural networks surpassed traditional approaches on the Tox21 Data Challenge. This milestone accelerated the adoption of deep learning across the pharmaceutical industry, and today most major companies have integrated th...",
        "published": "2025-11-18T18:43:42Z",
        "updated": "2025-11-18T18:43:42Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14744v1",
        "abs_url": "https://arxiv.org/abs/2511.14744v1",
        "categories": [
          "cs.LG"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.14743v1",
        "title": "Beyond Means: A Dynamic Framework for Predicting Customer Satisfaction",
        "authors": [
          "Christof Naumzik",
          "Abdurahman Maarouf",
          "Stefan Feuerriegel",
          "Markus Weinmann"
        ],
        "abstract": "Online ratings influence customer decision-making, yet standard aggregation methods, such as the sample mean, fail to adapt to quality changes over time and ignore review heterogeneity (e.g., review sentiment, a review's helpfulness). To address these challenges, we demonstrate the value of using the Gaussian process (GP) framework for rating aggregation. Specifically, we present a tailored GP model that captures the dynamics of ratings over time while additionally accounting for review heteroge...",
        "published": "2025-11-18T18:43:29Z",
        "updated": "2025-11-18T18:43:29Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14743v1",
        "abs_url": "https://arxiv.org/abs/2511.14743v1",
        "categories": [
          "cs.LG"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.14738v1",
        "title": "LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data",
        "authors": [
          "Tzu-Hsuan Chou",
          "Chun-Nan Chou"
        ],
        "abstract": "Large language models (LLMs) have shown a remarkable ability to generalize beyond their pre-training data, and fine-tuning LLMs can elevate performance to human-level and beyond. However, in real-world scenarios, lacking labeled data often prevents practitioners from obtaining well-performing models, thereby forcing practitioners to highly rely on prompt-based approaches that are often tedious, inefficient, and driven by trial and error. To alleviate this issue of lacking labeled data, we presen...",
        "published": "2025-11-18T18:31:00Z",
        "updated": "2025-11-18T18:31:00Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14738v1",
        "abs_url": "https://arxiv.org/abs/2511.14738v1",
        "categories": [
          "cs.LG"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.14730v1",
        "title": "Heterogeneous Multi-Agent Proximal Policy Optimization for Power Distribution System Restoration",
        "authors": [
          "Parya Dolatyabi",
          "Mahdi Khodayar"
        ],
        "abstract": "Restoring power distribution systems (PDS) after large-scale outages requires sequential switching operations that reconfigure feeder topology and coordinate distributed energy resources (DERs) under nonlinear constraints such as power balance, voltage limits, and thermal ratings. These challenges make conventional optimization and value-based RL approaches computationally inefficient and difficult to scale. This paper applies a Heterogeneous-Agent Reinforcement Learning (HARL) framework, instan...",
        "published": "2025-11-18T18:23:35Z",
        "updated": "2025-11-18T18:23:35Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14730v1",
        "abs_url": "https://arxiv.org/abs/2511.14730v1",
        "categories": [
          "cs.AI"
        ],
        "primary_category": "cs.AI"
      },
      {
        "id": "2511.14728v1",
        "title": "Automated proving in planar geometry based on the complex number identity method and elimination",
        "authors": [
          "Zolt\u00e1n Kov\u00e1cs",
          "Xicheng Peng"
        ],
        "abstract": "We improve the complex number identity proving method to a fully automated procedure, based on elimination ideals. By using declarative equations or rewriting each real-relational hypothesis $h_i$ to $h_i-r_i$, and the thesis $t$ to $t-r$, clearing the denominators and introducing an extra expression with a slack variable, we eliminate all free and relational point variables. From the obtained ideal $I$ in $\\mathbb{Q}[r,r_1,r_2,\\ldots]$ we can find a conclusive result. It plays an important role...",
        "published": "2025-11-18T18:20:17Z",
        "updated": "2025-11-18T18:20:17Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14728v1",
        "abs_url": "https://arxiv.org/abs/2511.14728v1",
        "categories": [
          "cs.CG",
          "cs.AI"
        ],
        "primary_category": "cs.CG"
      },
      {
        "id": "2511.14721v1",
        "title": "AdamHD: Decoupled Huber Decay Regularization for Language Model Pre-Training",
        "authors": [
          "Fu-Ming Guo",
          "Yingfang Fan"
        ],
        "abstract": "Adaptive optimizers with decoupled weight decay, such as AdamW, are the de facto standard for pre-training large transformer-based generative models. Yet the quadratic nature of the $\\ell_2$ penalty embedded in weight decay drives all parameters toward the origin at the same rate, making the update vulnerable to rare but extreme gradient directions and often over-penalizing well-conditioned coordinates. We propose AdamHuberDecay, a drop-in replacement for AdamW that substitutes the $\\ell_2$ pena...",
        "published": "2025-11-18T18:08:20Z",
        "updated": "2025-11-18T18:08:20Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14721v1",
        "abs_url": "https://arxiv.org/abs/2511.14721v1",
        "categories": [
          "cs.LG",
          "math.OC"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.14719v1",
        "title": "Zero-shot Synthetic Video Realism Enhancement via Structure-aware Denoising",
        "authors": [
          "Yifan Wang",
          "Liya Ji",
          "Zhanghan Ke",
          "Harry Yang",
          "Ser-Nam Lim"
        ],
        "abstract": "We propose an approach to enhancing synthetic video realism, which can re-render synthetic videos from a simulator in photorealistic fashion. Our realism enhancement approach is a zero-shot framework that focuses on preserving the multi-level structures from synthetic videos into the enhanced one in both spatial and temporal domains, built upon a diffusion video foundational model without further fine-tuning. Specifically, we incorporate an effective modification to have the generation/denoising...",
        "published": "2025-11-18T18:06:29Z",
        "updated": "2025-11-18T18:06:29Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14719v1",
        "abs_url": "https://arxiv.org/abs/2511.14719v1",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2511.14715v1",
        "title": "\\textit{FLARE}: Adaptive Multi-Dimensional Reputation for Robust Client Reliability in Federated Learning",
        "authors": [
          "Abolfazl Younesi",
          "Leon Kiss",
          "Zahra Najafabadi Samani",
          "Juan Aznar Poveda",
          "Thomas Fahringer"
        ],
        "abstract": "Federated learning (FL) enables collaborative model training while preserving data privacy. However, it remains vulnerable to malicious clients who compromise model integrity through Byzantine attacks, data poisoning, or adaptive adversarial behaviors. Existing defense mechanisms rely on static thresholds and binary classification, failing to adapt to evolving client behaviors in real-world deployments. We propose FLARE, an adaptive reputation-based framework that transforms client reliability a...",
        "published": "2025-11-18T17:57:40Z",
        "updated": "2025-11-18T17:57:40Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14715v1",
        "abs_url": "https://arxiv.org/abs/2511.14715v1",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CR",
          "cs.DC",
          "cs.MA"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.14710v1",
        "title": "Towards a Unified Analysis of Neural Networks in Nonparametric Instrumental Variable Regression: Optimization and Generalization",
        "authors": [
          "Zonghao Chen",
          "Atsushi Nitanda",
          "Arthur Gretton",
          "Taiji Suzuki"
        ],
        "abstract": "We establish the first global convergence result of neural networks for two stage least squares (2SLS) approach in nonparametric instrumental variable regression (NPIV). This is achieved by adopting a lifted perspective through mean-field Langevin dynamics (MFLD), unlike standard MFLD, however, our setting of 2SLS entails a \\emph{bilevel} optimization problem in the space of probability measures. To address this challenge, we leverage the penalty gradient approach recently developed for bilevel ...",
        "published": "2025-11-18T17:51:17Z",
        "updated": "2025-11-18T17:51:17Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14710v1",
        "abs_url": "https://arxiv.org/abs/2511.14710v1",
        "categories": [
          "stat.ML",
          "cs.LG"
        ],
        "primary_category": "stat.ML"
      },
      {
        "id": "2511.14709v1",
        "title": "Strategic Innovation Management in the Age of Large Language Models Market Intelligence, Adaptive R&D, and Ethical Governance",
        "authors": [
          "Raha Aghaei",
          "Ali A. Kiaei",
          "Mahnaz Boush",
          "Mahan Rofoosheh",
          "Mohammad Zavvar"
        ],
        "abstract": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexib...",
        "published": "2025-11-18T17:50:39Z",
        "updated": "2025-11-18T17:50:39Z",
        "pdf_url": "https://arxiv.org/pdf/2511.14709v1",
        "abs_url": "https://arxiv.org/abs/2511.14709v1",
        "categories": [
          "cs.CL"
        ],
        "primary_category": "cs.CL"
      }
    ],
    "count": 15,
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.CL"
    ],
    "fetch_date": "2025-11-19"
  },
  "metadata": {
    "source": "arXiv API",
    "query": "cat:cs.AI OR cat:cs.LG OR cat:cs.CL",
    "deduplication": {
      "total_fetched": 15,
      "new_papers": 15,
      "duplicates_filtered": 0,
      "last_fetch": "2025-11-18T09:03:16.108058"
    }
  },
  "costs": {
    "execution_time": 0.6389179229736328,
    "execution_minutes": 0.010648632049560547,
    "github_actions": 8.518905639648438e-05,
    "openai": {
      "input": 0,
      "output": 0,
      "total": 0
    },
    "total": 8.518905639648438e-05,
    "token_usage": {}
  }
}