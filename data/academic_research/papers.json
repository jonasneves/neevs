{
  "agent": "agent-a-paper-fetcher",
  "timestamp": "2025-12-03T09:05:20.321173",
  "status": "completed",
  "data": {
    "papers": [
      {
        "id": "2512.03042v1",
        "title": "PPTArena: A Benchmark for Agentic PowerPoint Editing",
        "authors": [
          "Michael Ofengenden",
          "Yunze Man",
          "Ziqi Pang",
          "Yu-Xiong Wang"
        ],
        "abstract": "We introduce PPTArena, a benchmark for PowerPoint editing that measures reliable modifications to real slides under natural-language instructions. In contrast to image-PDF renderings or text-to-slide generation, PPTArena focuses on in-place editing across 100 decks, 2125 slides, and over 800 targeted edits covering text, charts, tables, animations, and master-level styles. Each case includes a ground-truth deck, a fully specified target outcome, and a dual VLM-as-judge pipeline that separately s...",
        "published": "2025-12-02T18:59:50Z",
        "updated": "2025-12-02T18:59:50Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03042v1",
        "abs_url": "https://arxiv.org/abs/2512.03042v1",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2512.03040v1",
        "title": "Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation",
        "authors": [
          "Zeqi Xiao",
          "Yiwei Zhao",
          "Lingxiao Li",
          "Yushi Lan",
          "Yu Ning"
        ],
        "abstract": "We investigate whether video generative models can exhibit visuospatial intelligence, a capability central to human cognition, using only visual data. To this end, we present Video4Spatial, a framework showing that video diffusion models conditioned solely on video-based scene context can perform complex spatial tasks. We validate on two tasks: scene navigation - following camera-pose instructions while remaining consistent with 3D geometry of the scene, and object grounding - which requires sem...",
        "published": "2025-12-02T18:59:44Z",
        "updated": "2025-12-02T18:59:44Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03040v1",
        "abs_url": "https://arxiv.org/abs/2512.03040v1",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2512.03036v1",
        "title": "ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation",
        "authors": [
          "Mengchen Zhang",
          "Qi Chen",
          "Tong Wu",
          "Zihan Liu",
          "Dahua Lin"
        ],
        "abstract": "Despite progress in video-to-audio generation, the field focuses predominantly on mono output, lacking spatial immersion. Existing binaural approaches remain constrained by a two-stage pipeline that first generates mono audio and then performs spatialization, often resulting in error accumulation and spatio-temporal inconsistencies. To address this limitation, we introduce the task of end-to-end binaural spatial audio generation directly from silent video. To support this task, we present the Bi...",
        "published": "2025-12-02T18:56:12Z",
        "updated": "2025-12-02T18:56:12Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03036v1",
        "abs_url": "https://arxiv.org/abs/2512.03036v1",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2512.03035v1",
        "title": "Learning Physically Consistent Lagrangian Control Models Without Acceleration Measurements",
        "authors": [
          "Ibrahim Laiche",
          "Mokrane Boudaoud",
          "Patrick Gallinari",
          "Pascal Morin"
        ],
        "abstract": "This article investigates the modeling and control of Lagrangian systems involving non-conservative forces using a hybrid method that does not require acceleration calculations. It focuses in particular on the derivation and identification of physically consistent models, which are essential for model-based control synthesis. Lagrangian or Hamiltonian neural networks provide useful structural guarantees but the learning of such models often leads to inconsistent models, especially on real physic...",
        "published": "2025-12-02T18:56:02Z",
        "updated": "2025-12-02T18:56:02Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03035v1",
        "abs_url": "https://arxiv.org/abs/2512.03035v1",
        "categories": [
          "eess.SY",
          "cs.LG"
        ],
        "primary_category": "eess.SY"
      },
      {
        "id": "2512.03028v1",
        "title": "SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control",
        "authors": [
          "Yuxuan Mu",
          "Ziyu Zhang",
          "Yi Shi",
          "Minami Matsumoto",
          "Kotaro Imamura"
        ],
        "abstract": "Data-driven motion priors that can guide agents toward producing naturalistic behaviors play a pivotal role in creating life-like virtual characters. Adversarial imitation learning has been a highly effective method for learning motion priors from reference motion data. However, adversarial priors, with few exceptions, need to be retrained for each new controller, thereby limiting their reusability and necessitating the retention of the reference motion data when training on downstream tasks. In...",
        "published": "2025-12-02T18:54:12Z",
        "updated": "2025-12-02T18:54:12Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03028v1",
        "abs_url": "https://arxiv.org/abs/2512.03028v1",
        "categories": [
          "cs.GR",
          "cs.AI",
          "cs.CV",
          "cs.RO"
        ],
        "primary_category": "cs.GR"
      },
      {
        "id": "2512.03026v1",
        "title": "The Moral Consistency Pipeline: Continuous Ethical Evaluation for Large Language Models",
        "authors": [
          "Saeid Jamshidi",
          "Kawser Wazed Nafi",
          "Arghavan Moradi Dakhel",
          "Negar Shahabi",
          "Foutse Khomh"
        ],
        "abstract": "The rapid advancement and adaptability of Large Language Models (LLMs) highlight the need for moral consistency, the capacity to maintain ethically coherent reasoning across varied contexts. Existing alignment frameworks, structured approaches designed to align model behavior with human ethical and social norms, often rely on static datasets and post-hoc evaluations, offering limited insight into how ethical reasoning may evolve across different contexts or temporal scales. This study presents t...",
        "published": "2025-12-02T18:52:29Z",
        "updated": "2025-12-02T18:52:29Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03026v1",
        "abs_url": "https://arxiv.org/abs/2512.03026v1",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2512.03025v1",
        "title": "LORE: A Large Generative Model for Search Relevance",
        "authors": [
          "Chenji Lu",
          "Zhuo Chen",
          "Hui Zhao",
          "Zhiyuan Zeng",
          "Gang Zhao"
        ],
        "abstract": "Achievement. We introduce LORE, a systematic framework for Large Generative Model-based relevance in e-commerce search. Deployed and iterated over three years, LORE achieves a cumulative +27\\% improvement in online GoodRate metrics. This report shares the valuable experience gained throughout its development lifecycle, spanning data, features, training, evaluation, and deployment. Insight. While existing works apply Chain-of-Thought (CoT) to enhance relevance, they often hit a performance ceilin...",
        "published": "2025-12-02T18:50:42Z",
        "updated": "2025-12-02T18:50:42Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03025v1",
        "abs_url": "https://arxiv.org/abs/2512.03025v1",
        "categories": [
          "cs.IR",
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ],
        "primary_category": "cs.IR"
      },
      {
        "id": "2512.03024v1",
        "title": "TokenPowerBench: Benchmarking the Power Consumption of LLM Inference",
        "authors": [
          "Chenxu Niu",
          "Wei Zhang",
          "Jie Li",
          "Yongjian Zhao",
          "Tongyang Wang"
        ],
        "abstract": "Large language model (LLM) services now answer billions of queries per day, and industry reports show that inference, not training, accounts for more than 90% of total power consumption. However, existing benchmarks focus on either training/fine-tuning or performance of inference and provide little support for power consumption measurement and analysis of inference. We introduce TokenPowerBench, the first lightweight and extensible benchmark designed for LLM-inference power consumption studies. ...",
        "published": "2025-12-02T18:50:17Z",
        "updated": "2025-12-02T18:50:17Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03024v1",
        "abs_url": "https://arxiv.org/abs/2512.03024v1",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CY",
          "cs.DC"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.03019v1",
        "title": "Distribution-Calibrated Inference time compute for Thinking LLM-as-a-Judge",
        "authors": [
          "Hamid Dadkhahi",
          "Firas Trabelsi",
          "Parker Riley",
          "Juraj Juraska",
          "Mehdi Mirzazadeh"
        ],
        "abstract": "Thinking Large Language Models (LLMs) used as judges for pairwise preferences remain noisy at the single-sample level, and common aggregation rules (majority vote, soft self-consistency, or instruction-based self-aggregation) are inconsistent when ties are allowed. We study inference-time compute (ITC) for evaluators that generate n independent thinking-rating samples per item, and propose a principled, distribution-calibrated aggregation scheme. Our method models three-way preferences with a Br...",
        "published": "2025-12-02T18:46:47Z",
        "updated": "2025-12-02T18:46:47Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03019v1",
        "abs_url": "https://arxiv.org/abs/2512.03019v1",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.03013v1",
        "title": "In-Context Sync-LoRA for Portrait Video Editing",
        "authors": [
          "Sagi Polaczek",
          "Or Patashnik",
          "Ali Mahdavi-Amiri",
          "Daniel Cohen-Or"
        ],
        "abstract": "Editing portrait videos is a challenging task that requires flexible yet precise control over a wide range of modifications, such as appearance changes, expression edits, or the addition of objects. The key difficulty lies in preserving the subject's original temporal behavior, demanding that every edited frame remains precisely synchronized with the corresponding source frame. We present Sync-LoRA, a method for editing portrait videos that achieves high-quality visual modifications while mainta...",
        "published": "2025-12-02T18:40:35Z",
        "updated": "2025-12-02T18:40:35Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03013v1",
        "abs_url": "https://arxiv.org/abs/2512.03013v1",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.GR"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2512.03005v1",
        "title": "From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?",
        "authors": [
          "Dawei Li",
          "Abdullah Alnaibari",
          "Arslan Bisharat",
          "Manny Sandoval",
          "Deborah Hall"
        ],
        "abstract": "The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two s...",
        "published": "2025-12-02T18:31:18Z",
        "updated": "2025-12-02T18:31:18Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03005v1",
        "abs_url": "https://arxiv.org/abs/2512.03005v1",
        "categories": [
          "cs.AI"
        ],
        "primary_category": "cs.AI"
      },
      {
        "id": "2512.03001v1",
        "title": "Invasive Context Engineering to Control Large Language Models",
        "authors": [
          "Thomas Rivasseau"
        ],
        "abstract": "Current research on operator control of Large Language Models improves model robustness against adversarial attacks and misbehavior by training on preference examples, prompting, and input/output filtering. Despite good results, LLMs remain susceptible to abuse, and jailbreak probability increases with context length. There is a need for robust LLM security guarantees in long-context situations. We propose control sentences inserted into the LLM context as invasive context engineering to partial...",
        "published": "2025-12-02T18:25:55Z",
        "updated": "2025-12-02T18:25:55Z",
        "pdf_url": "https://arxiv.org/pdf/2512.03001v1",
        "abs_url": "https://arxiv.org/abs/2512.03001v1",
        "categories": [
          "cs.AI"
        ],
        "primary_category": "cs.AI"
      },
      {
        "id": "2512.02987v1",
        "title": "Fine-Tuned Large Language Models for Logical Translation: Reducing Hallucinations with Lang2Logic",
        "authors": [
          "Muyu Pan",
          "Dheeraj Kodakandla",
          "Mahfuza Farooque"
        ],
        "abstract": "Recent advances in natural language processing (NLP), particularly large language models (LLMs), have motivated the automatic translation of natural language statements into formal logic without human intervention. This enables automated reasoning and facilitates debugging, finding loop invariants, and adhering to specifications in software systems. However, hallucinations-incorrect outputs generated by LLMs are challenging, particularly for logical translation tasks requiring precision. This wo...",
        "published": "2025-12-02T18:03:06Z",
        "updated": "2025-12-02T18:03:06Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02987v1",
        "abs_url": "https://arxiv.org/abs/2512.02987v1",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2512.02983v1",
        "title": "ProteinPNet: Prototypical Part Networks for Concept Learning in Spatial Proteomics",
        "authors": [
          "Louis McConnell",
          "Jieran Sun",
          "Theo Maffei",
          "Raphael Gottardo",
          "Marianna Rapsomaniki"
        ],
        "abstract": "Understanding the spatial architecture of the tumor microenvironment (TME) is critical to advance precision oncology. We present ProteinPNet, a novel framework based on prototypical part networks that discovers TME motifs from spatial proteomics data. Unlike traditional post-hoc explanability models, ProteinPNet directly learns discriminative, interpretable, faithful spatial prototypes through supervised training. We validate our approach on synthetic datasets with ground truth motifs, and furth...",
        "published": "2025-12-02T18:00:03Z",
        "updated": "2025-12-02T18:00:03Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02983v1",
        "abs_url": "https://arxiv.org/abs/2512.02983v1",
        "categories": [
          "cs.LG"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.02978v1",
        "title": "Rethinking Generalized BCIs: Benchmarking 340,000+ Unique Algorithmic Configurations for EEG Mental Command Decoding",
        "authors": [
          "Paul Barbaste",
          "Olivier Oullier",
          "Xavier Vasques"
        ],
        "abstract": "Robust decoding and classification of brain patterns measured with electroencephalography (EEG) remains a major challenge for real-world (i.e. outside scientific lab and medical facilities) brain-computer interface (BCI) applications due to well documented inter- and intra-participant variability. Here, we present a large-scale benchmark evaluating over 340,000+ unique combinations of spatial and nonlinear EEG classification. Our methodological pipeline consists in combinations of Common Spatial...",
        "published": "2025-12-02T17:56:46Z",
        "updated": "2025-12-02T17:56:46Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02978v1",
        "abs_url": "https://arxiv.org/abs/2512.02978v1",
        "categories": [
          "q-bio.NC",
          "cs.AI",
          "cs.HC",
          "cs.LG"
        ],
        "primary_category": "q-bio.NC"
      }
    ],
    "count": 15,
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.CL"
    ],
    "fetch_date": "2025-12-03"
  },
  "metadata": {
    "source": "arXiv API",
    "query": "cat:cs.AI OR cat:cs.LG OR cat:cs.CL",
    "deduplication": {
      "total_fetched": 15,
      "new_papers": 15,
      "duplicates_filtered": 0,
      "last_fetch": "2025-12-02T09:05:39.074003"
    }
  },
  "costs": {
    "execution_time": 0.40001487731933594,
    "execution_minutes": 0.006666914621988932,
    "github_actions": 5.333531697591146e-05,
    "openai": {
      "input": 0,
      "output": 0,
      "total": 0
    },
    "total": 5.333531697591146e-05,
    "token_usage": {}
  }
}