{
  "agent": "agent-a-paper-fetcher",
  "timestamp": "2025-11-15T09:02:54.379881",
  "status": "completed",
  "data": {
    "papers": [
      {
        "id": "2511.10645v1",
        "title": "ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference",
        "authors": [
          "Yesheng Liang",
          "Haisheng Chen",
          "Song Han",
          "Zhijian Liu"
        ],
        "abstract": "Weight-only post-training quantization (PTQ) compresses the weights of Large Language Models (LLMs) into low-precision representations to reduce memory footprint and accelerate inference. However, the presence of outliers in weights and activations often leads to large quantization errors and severe accuracy degradation, especially in recent reasoning LLMs where errors accumulate across long chains of thought. Existing PTQ methods either fail to sufficiently suppress outliers or introduce signif...",
        "published": "2025-11-13T18:59:24Z",
        "updated": "2025-11-13T18:59:24Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10645v1",
        "abs_url": "https://arxiv.org/abs/2511.10645v1",
        "categories": [
          "cs.CL"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2511.10643v1",
        "title": "Black-Box On-Policy Distillation of Large Language Models",
        "authors": [
          "Tianzhu Ye",
          "Li Dong",
          "Zewen Chi",
          "Xun Wu",
          "Shaohan Huang"
        ],
        "abstract": "Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy rewa...",
        "published": "2025-11-13T18:58:37Z",
        "updated": "2025-11-13T18:58:37Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10643v1",
        "abs_url": "https://arxiv.org/abs/2511.10643v1",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2511.10635v1",
        "title": "Robot Crash Course: Learning Soft and Stylized Falling",
        "authors": [
          "Pascal Strauch",
          "David M\u00fcller",
          "Sammy Christen",
          "Agon Serifi",
          "Ruben Grandia"
        ],
        "abstract": "Despite recent advances in robust locomotion, bipedal robots operating in the real world remain at risk of falling. While most research focuses on preventing such events, we instead concentrate on the phenomenon of falling itself. Specifically, we aim to reduce physical damage to the robot while providing users with control over a robot's end pose. To this end, we propose a robot agnostic reward function that balances the achievement of a desired end pose with impact minimization and the protect...",
        "published": "2025-11-13T18:55:34Z",
        "updated": "2025-11-13T18:55:34Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10635v1",
        "abs_url": "https://arxiv.org/abs/2511.10635v1",
        "categories": [
          "cs.RO",
          "cs.LG"
        ],
        "primary_category": "cs.RO"
      },
      {
        "id": "2511.10628v1",
        "title": "Instella: Fully Open Language Models with Stellar Performance",
        "authors": [
          "Jiang Liu",
          "Jialian Wu",
          "Xiaodong Yu",
          "Yusheng Su",
          "Prakamya Mishra"
        ],
        "abstract": "Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks, yet the majority of high-performing models remain closed-source or partially open, limiting transparency and reproducibility. In this work, we introduce Instella, a family of fully open three billion parameter language models trained entirely on openly available data and codebase. Powered by AMD Instinct MI300X GPUs, Instella is developed through large-scale pre-training, general-purpose instructi...",
        "published": "2025-11-13T18:52:46Z",
        "updated": "2025-11-13T18:52:46Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10628v1",
        "abs_url": "https://arxiv.org/abs/2511.10628v1",
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2511.10627v1",
        "title": "Querying Labeled Time Series Data with Scenario Programs",
        "authors": [
          "Edward Kim",
          "Devan Shanker",
          "Varun Bharadwaj",
          "Hongbeen Park",
          "Jinkyu Kim"
        ],
        "abstract": "Simulation-based testing has become a crucial complement to road testing for ensuring the safety of cyber physical systems (CPS). As a result, significant research efforts have been directed toward identifying failure scenarios within simulation environments. However, a critical question remains. Are the AV failure scenarios discovered in simulation reproducible on actual systems in the real world? The sim-to-real gap caused by differences between simulated and real sensor data means that failur...",
        "published": "2025-11-13T18:52:27Z",
        "updated": "2025-11-13T18:52:27Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10627v1",
        "abs_url": "https://arxiv.org/abs/2511.10627v1",
        "categories": [
          "cs.AI",
          "cs.CV",
          "cs.FL",
          "cs.LG"
        ],
        "primary_category": "cs.AI"
      },
      {
        "id": "2511.10626v1",
        "title": "Global Solutions to Non-Convex Functional Constrained Problems with Hidden Convexity",
        "authors": [
          "Ilyas Fatkhullin",
          "Niao He",
          "Guanghui Lan",
          "Florian Wolf"
        ],
        "abstract": "Constrained non-convex optimization is fundamentally challenging, as global solutions are generally intractable and constraint qualifications may not hold. However, in many applications, including safe policy optimization in control and reinforcement learning, such problems possess hidden convexity, meaning they can be reformulated as convex programs via a nonlinear invertible transformation. Typically such transformations are implicit or unknown, making the direct link with the convex program i...",
        "published": "2025-11-13T18:51:00Z",
        "updated": "2025-11-13T18:51:00Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10626v1",
        "abs_url": "https://arxiv.org/abs/2511.10626v1",
        "categories": [
          "math.OC",
          "cs.LG"
        ],
        "primary_category": "math.OC"
      },
      {
        "id": "2511.10621v1",
        "title": "SSR: Socratic Self-Refine for Large Language Model Reasoning",
        "authors": [
          "Haizhou Shi",
          "Ye Liu",
          "Bo Pang",
          "Zeyu Leo Liu",
          "Hao Wang"
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, yet existing test-time frameworks often rely on coarse self-verification and self-correction, limiting their effectiveness on complex tasks. In this paper, we propose Socratic Self-Refine (SSR), a novel framework for fine-grained evaluation and precise refinement of LLM reasoning. Our proposed SSR decomposes model responses into verifiable (sub-question, sub-answer) pairs, enabling step-level confidence estimation thr...",
        "published": "2025-11-13T18:47:07Z",
        "updated": "2025-11-13T18:47:07Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10621v1",
        "abs_url": "https://arxiv.org/abs/2511.10621v1",
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2511.10619v1",
        "title": "Algorithm Design and Stronger Guarantees for the Improving Multi-Armed Bandits Problem",
        "authors": [
          "Avrim Blum",
          "Marten Garicano",
          "Kavya Ravichandran",
          "Dravyansh Sharma"
        ],
        "abstract": "The improving multi-armed bandits problem is a formal model for allocating effort under uncertainty, motivated by scenarios such as investing research effort into new technologies, performing clinical trials, and hyperparameter selection from learning curves. Each pull of an arm provides reward that increases monotonically with diminishing returns. A growing line of work has designed algorithms for improving bandits, albeit with somewhat pessimistic worst-case guarantees. Indeed, strong lower bo...",
        "published": "2025-11-13T18:46:56Z",
        "updated": "2025-11-13T18:46:56Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10619v1",
        "abs_url": "https://arxiv.org/abs/2511.10619v1",
        "categories": [
          "cs.LG",
          "stat.ML"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2511.10618v1",
        "title": "Know Your Limits: Entropy Estimation Modeling for Compression and Generalization",
        "authors": [
          "Benjamin L. Badger",
          "Matthew Neligeorge"
        ],
        "abstract": "Language prediction is constrained by informational entropy intrinsic to language, such that there exists a limit to how accurate any language model can become and equivalently a lower bound to language compression. The most efficient language compression algorithms today are causal (next token prediction) large language models, but the use of these models to form accurate estimates of language entropy is currently computationally infeasible. We introduce encoder-augmented causal decoder model a...",
        "published": "2025-11-13T18:46:42Z",
        "updated": "2025-11-13T18:46:42Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10618v1",
        "abs_url": "https://arxiv.org/abs/2511.10618v1",
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.IT",
          "cs.LG"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2511.10615v1",
        "title": "Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals",
        "authors": [
          "Shruti Singh Baghel",
          "Yash Pratap Singh Rathore",
          "Sushovan Jena",
          "Anurag Pradhan",
          "Amit Shukla"
        ],
        "abstract": "Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, w...",
        "published": "2025-11-13T18:45:39Z",
        "updated": "2025-11-13T18:45:39Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10615v1",
        "abs_url": "https://arxiv.org/abs/2511.10615v1",
        "categories": [
          "cs.CV",
          "cs.CL"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2511.10611v1",
        "title": "Towards an Agentic Workflow for Internet Measurement Research",
        "authors": [
          "Alagappan Ramanathan",
          "Eunju Kang",
          "Dongsu Han",
          "Sangeetha Abdu Jyothi"
        ],
        "abstract": "Internet measurement research faces an accessibility crisis: complex analyses require custom integration of multiple specialized tools that demands specialized domain expertise. When network disruptions occur, operators need rapid diagnostic workflows spanning infrastructure mapping, routing analysis, and dependency modeling. However, developing these workflows requires specialized knowledge and significant manual effort.\n  We present ArachNet, the first system demonstrating that LLM agents can ...",
        "published": "2025-11-13T18:44:09Z",
        "updated": "2025-11-13T18:44:09Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10611v1",
        "abs_url": "https://arxiv.org/abs/2511.10611v1",
        "categories": [
          "cs.NI",
          "cs.AI"
        ],
        "primary_category": "cs.NI"
      },
      {
        "id": "2511.10604v1",
        "title": "Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping",
        "authors": [
          "Zack Dewis",
          "Yimin Zhu",
          "Zhengsen Xu",
          "Mabel Heffring",
          "Saeid Taleghanidoozdoozan"
        ],
        "abstract": "Although Sentinel-2 based land use and land cover (LULC) classification is critical for various environmental monitoring applications, it is a very difficult task due to some key data challenges (e.g., spatial heterogeneity, context information, signature ambiguity). This paper presents a novel Multitask Glocal OBIA-Mamba (MSOM) for enhanced Sentinel-2 classification with the following contributions. First, an object-based image analysis (OBIA) Mamba model (OBIA-Mamba) is designed to reduce redu...",
        "published": "2025-11-13T18:40:22Z",
        "updated": "2025-11-13T18:40:22Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10604v1",
        "abs_url": "https://arxiv.org/abs/2511.10604v1",
        "categories": [
          "cs.CV",
          "cs.LG"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2511.10593v1",
        "title": "Regular Games -- an Automata-Based General Game Playing Language",
        "authors": [
          "Rados\u0142aw Miernik",
          "Marek Szyku\u0142a",
          "Jakub Kowalski",
          "Jakub Cie\u015bluk",
          "\u0141ukasz Galas"
        ],
        "abstract": "We propose a new General Game Playing (GGP) system called Regular Games (RG). The main goal of RG is to be both computationally efficient and convenient for game design. The system consists of several languages. The core component is a low-level language that defines the rules by a finite automaton. It is minimal with only a few mechanisms, which makes it easy for automatic processing (by agents, analysis, optimization, etc.). The language is universal for the class of all finite turn-based game...",
        "published": "2025-11-13T18:29:27Z",
        "updated": "2025-11-13T18:29:27Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10593v1",
        "abs_url": "https://arxiv.org/abs/2511.10593v1",
        "categories": [
          "cs.AI"
        ],
        "primary_category": "cs.AI"
      },
      {
        "id": "2511.10591v1",
        "title": "Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering",
        "authors": [
          "Bavana Durgapraveen",
          "Sornaraj Sivasankaran",
          "Abhinand Balachandran",
          "Sriram Rajkumar"
        ],
        "abstract": "The rapid expansion of asynchronous remote care has intensified provider workload, creating demand for AI systems that can assist clinicians in managing patient queries more efficiently. The MEDIQA-WV 2025 shared task addresses this challenge by focusing on generating free-text responses to wound care queries paired with images. In this work, we present two complementary approaches developed for the English track. The first leverages a mined prompting strategy, where training data is embedded an...",
        "published": "2025-11-13T18:28:58Z",
        "updated": "2025-11-13T18:28:58Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10591v1",
        "abs_url": "https://arxiv.org/abs/2511.10591v1",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2511.10590v1",
        "title": "Pretrained Joint Predictions for Scalable Batch Bayesian Optimization of Molecular Designs",
        "authors": [
          "Miles Wang-Henderson",
          "Ben Kaufman",
          "Edward Williams",
          "Ryan Pederson",
          "Matteo Rossi"
        ],
        "abstract": "Batched synthesis and testing of molecular designs is the key bottleneck of drug development. There has been great interest in leveraging biomolecular foundation models as surrogates to accelerate this process. In this work, we show how to obtain scalable probabilistic surrogates of binding affinity for use in Batch Bayesian Optimization (Batch BO). This demands parallel acquisition functions that hedge between designs and the ability to rapidly sample from a joint predictive density to approxim...",
        "published": "2025-11-13T18:26:58Z",
        "updated": "2025-11-13T18:26:58Z",
        "pdf_url": "https://arxiv.org/pdf/2511.10590v1",
        "abs_url": "https://arxiv.org/abs/2511.10590v1",
        "categories": [
          "cs.LG"
        ],
        "primary_category": "cs.LG"
      }
    ],
    "count": 15,
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.CL"
    ],
    "fetch_date": "2025-11-15"
  },
  "metadata": {
    "source": "arXiv API",
    "query": "cat:cs.AI OR cat:cs.LG OR cat:cs.CL",
    "deduplication": {
      "total_fetched": 15,
      "new_papers": 15,
      "duplicates_filtered": 0,
      "last_fetch": "2025-11-14T09:03:27.657343"
    }
  },
  "costs": {
    "execution_time": 0.4196469783782959,
    "execution_minutes": 0.006994116306304932,
    "github_actions": 5.5952930450439456e-05,
    "openai": {
      "input": 0,
      "output": 0,
      "total": 0
    },
    "total": 5.5952930450439456e-05,
    "token_usage": {}
  }
}