{
  "agent": "agent-a-paper-fetcher",
  "timestamp": "2025-12-02T09:05:39.074003",
  "status": "completed",
  "data": {
    "papers": [
      {
        "id": "2512.02020v1",
        "title": "EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI",
        "authors": [
          "Jianlei Chang",
          "Ruofeng Mei",
          "Wei Ke",
          "Xiangyu Xu"
        ],
        "abstract": "Generative modeling has recently shown remarkable promise for visuomotor policy learning, enabling flexible and expressive control across diverse embodied AI tasks. However, existing generative policies often struggle with data inefficiency, requiring large-scale demonstrations, and sampling inefficiency, incurring slow action generation during inference. We introduce EfficientFlow, a unified framework for efficient embodied AI with flow-based policy learning. To enhance data efficiency, we brin...",
        "published": "2025-12-01T18:59:59Z",
        "updated": "2025-12-01T18:59:59Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02020v1",
        "abs_url": "https://arxiv.org/abs/2512.02020v1",
        "categories": [
          "cs.RO",
          "cs.AI",
          "cs.CV",
          "cs.LG"
        ],
        "primary_category": "cs.RO"
      },
      {
        "id": "2512.02019v1",
        "title": "A Diffusion Model Framework for Maximum Entropy Reinforcement Learning",
        "authors": [
          "Sebastian Sanokowski",
          "Kaustubh Patil",
          "Alois Knoll"
        ],
        "abstract": "Diffusion models have achieved remarkable success in data-driven learning and in sampling from complex, unnormalized target distributions. Building on this progress, we reinterpret Maximum Entropy Reinforcement Learning (MaxEntRL) as a diffusion model-based sampling problem. We tackle this problem by minimizing the reverse Kullback-Leibler (KL) divergence between the diffusion policy and the optimal policy distribution using a tractable upper bound. By applying the policy gradient theorem to thi...",
        "published": "2025-12-01T18:59:58Z",
        "updated": "2025-12-01T18:59:58Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02019v1",
        "abs_url": "https://arxiv.org/abs/2512.02019v1",
        "categories": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.02017v1",
        "title": "Visual Sync: Multi-Camera Synchronization via Cross-View Object Motion",
        "authors": [
          "Shaowei Liu",
          "David Yifan Yao",
          "Saurabh Gupta",
          "Shenlong Wang"
        ],
        "abstract": "Today, people can easily record memorable moments, ranging from concerts, sports events, lectures, family gatherings, and birthday parties with multiple consumer cameras. However, synchronizing these cross-camera streams remains challenging. Existing methods assume controlled settings, specific targets, manual correction, or costly hardware. We present VisualSync, an optimization framework based on multi-view dynamics that aligns unposed, unsynchronized videos at millisecond accuracy. Our key in...",
        "published": "2025-12-01T18:59:57Z",
        "updated": "2025-12-01T18:59:57Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02017v1",
        "abs_url": "https://arxiv.org/abs/2512.02017v1",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG",
          "cs.RO"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2512.02012v1",
        "title": "Improved Mean Flows: On the Challenges of Fastforward Generative Models",
        "authors": [
          "Zhengyang Geng",
          "Yiyang Lu",
          "Zongze Wu",
          "Eli Shechtman",
          "J. Zico Kolter"
        ],
        "abstract": "MeanFlow (MF) has recently been established as a framework for one-step generative modeling. However, its ``fastforward'' nature introduces key challenges in both the training objective and the guidance mechanism. First, the original MF's training target depends not only on the underlying ground-truth fields but also on the network itself. To address this issue, we recast the objective as a loss on the instantaneous velocity $v$, re-parameterized by a network that predicts the average velocity $...",
        "published": "2025-12-01T18:59:49Z",
        "updated": "2025-12-01T18:59:49Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02012v1",
        "abs_url": "https://arxiv.org/abs/2512.02012v1",
        "categories": [
          "cs.CV",
          "cs.LG"
        ],
        "primary_category": "cs.CV"
      },
      {
        "id": "2512.02010v1",
        "title": "Four Over Six: More Accurate NVFP4 Quantization with Adaptive Block Scaling",
        "authors": [
          "Jack Cook",
          "Junxian Guo",
          "Guangxuan Xiao",
          "Yujun Lin",
          "Song Han"
        ],
        "abstract": "As large language models have grown larger, low-precision numerical formats such as NVFP4 have become increasingly popular due to the speed and memory benefits they provide. However, to accelerate computation with NVFP4, all matrix multiplication operands--weights and activations in the forward pass, and weights, activations, and gradients in the backward pass--must be quantized to NVFP4, often leading to divergence during training and performance degradation during inference. NVFP4 by evaluatin...",
        "published": "2025-12-01T18:59:45Z",
        "updated": "2025-12-01T18:59:45Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02010v1",
        "abs_url": "https://arxiv.org/abs/2512.02010v1",
        "categories": [
          "cs.CL",
          "cs.LG"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2512.02008v1",
        "title": "The Art of Scaling Test-Time Compute for Large Language Models",
        "authors": [
          "Aradhye Agarwal",
          "Ayan Sengupta",
          "Tanmoy Chakraborty"
        ],
        "abstract": "Test-time scaling (TTS) -- the dynamic allocation of compute during inference -- is a promising direction for improving reasoning in large language models (LLMs). However, a systematic comparison of well-known TTS strategies under identical conditions is missing, and the influence of model type and problem difficulty on performance remains unclear. To address these gaps, we conduct the first large-scale study of TTS, spanning over thirty billion tokens generated using eight open-source LLMs (7B ...",
        "published": "2025-12-01T18:59:28Z",
        "updated": "2025-12-01T18:59:28Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02008v1",
        "abs_url": "https://arxiv.org/abs/2512.02008v1",
        "categories": [
          "cs.CL"
        ],
        "primary_category": "cs.CL"
      },
      {
        "id": "2512.02004v1",
        "title": "AlignSAE: Concept-Aligned Sparse Autoencoders",
        "authors": [
          "Minglai Yang",
          "Xinyu Guo",
          "Mihai Surdeanu",
          "Liangming Pan"
        ],
        "abstract": "Large Language Models (LLMs) encode factual knowledge within hidden parametric spaces that are difficult to inspect or control. While Sparse Autoencoders (SAEs) can decompose hidden activations into more fine-grained, interpretable features, they often struggle to reliably align these features with human-defined concepts, resulting in entangled and distributed feature representations. To address this, we introduce AlignSAE, a method that aligns SAE features with a defined ontology through a \"pre...",
        "published": "2025-12-01T18:58:22Z",
        "updated": "2025-12-01T18:58:22Z",
        "pdf_url": "https://arxiv.org/pdf/2512.02004v1",
        "abs_url": "https://arxiv.org/abs/2512.02004v1",
        "categories": [
          "cs.LG",
          "cs.CL"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.01996v1",
        "title": "Learning Sim-to-Real Humanoid Locomotion in 15 Minutes",
        "authors": [
          "Younggyo Seo",
          "Carmelo Sferrazza",
          "Juyue Chen",
          "Guanya Shi",
          "Rocky Duan"
        ],
        "abstract": "Massively parallel simulation has reduced reinforcement learning (RL) training time for robots from days to minutes. However, achieving fast and reliable sim-to-real RL for humanoid control remains difficult due to the challenges introduced by factors such as high dimensionality and domain randomization. In this work, we introduce a simple and practical recipe based on off-policy RL algorithms, i.e., FastSAC and FastTD3, that enables rapid training of humanoid locomotion policies in just 15 minu...",
        "published": "2025-12-01T18:55:17Z",
        "updated": "2025-12-01T18:55:17Z",
        "pdf_url": "https://arxiv.org/pdf/2512.01996v1",
        "abs_url": "https://arxiv.org/abs/2512.01996v1",
        "categories": [
          "cs.RO",
          "cs.AI",
          "cs.LG"
        ],
        "primary_category": "cs.RO"
      },
      {
        "id": "2512.01993v1",
        "title": "RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies",
        "authors": [
          "Guillermo Garcia-Cobo",
          "Maximilian Igl",
          "Peter Karkus",
          "Zhejun Zhang",
          "Michael Watson"
        ],
        "abstract": "Autonomous driving policies are typically trained via open-loop behavior cloning of human demonstrations. However, such policies suffer from covariate shift when deployed in closed loop, leading to compounding errors. We introduce Rollouts as Demonstrations (RoaD), a simple and efficient method to mitigate covariate shift by leveraging the policy's own closed-loop rollouts as additional training data. During rollout generation, RoaD incorporates expert guidance to bias trajectories toward high-q...",
        "published": "2025-12-01T18:52:03Z",
        "updated": "2025-12-01T18:52:03Z",
        "pdf_url": "https://arxiv.org/pdf/2512.01993v1",
        "abs_url": "https://arxiv.org/abs/2512.01993v1",
        "categories": [
          "cs.RO",
          "cs.AI",
          "cs.CV",
          "cs.LG"
        ],
        "primary_category": "cs.RO"
      },
      {
        "id": "2512.01992v1",
        "title": "LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess",
        "authors": [
          "Sai Kolasani",
          "Maxim Saplin",
          "Nicholas Crispino",
          "Kyle Montgomery",
          "Jared Quincy Davis"
        ],
        "abstract": "We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an El...",
        "published": "2025-12-01T18:51:08Z",
        "updated": "2025-12-01T18:51:08Z",
        "pdf_url": "https://arxiv.org/pdf/2512.01992v1",
        "abs_url": "https://arxiv.org/abs/2512.01992v1",
        "categories": [
          "cs.AI",
          "cs.CL"
        ],
        "primary_category": "cs.AI"
      },
      {
        "id": "2512.01987v1",
        "title": "Forecasting in Offline Reinforcement Learning for Non-stationary Environments",
        "authors": [
          "Suzan Ece Ada",
          "Georg Martius",
          "Emre Ugur",
          "Erhan Oztop"
        ],
        "abstract": "Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade per...",
        "published": "2025-12-01T18:45:05Z",
        "updated": "2025-12-01T18:45:05Z",
        "pdf_url": "https://arxiv.org/pdf/2512.01987v1",
        "abs_url": "https://arxiv.org/abs/2512.01987v1",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.RO"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.01986v1",
        "title": "A robust generalizable device-agnostic deep learning model for sleep-wake determination from triaxial wrist accelerometry",
        "authors": [
          "Nasim Montazeri",
          "Stone Yang",
          "Dominik Luszczynski",
          "John Zhang",
          "Dharmendra Gurve"
        ],
        "abstract": "Study Objectives: Wrist accelerometry is widely used for inferring sleep-wake state. Previous works demonstrated poor wake detection, without cross-device generalizability and validation in different age range and sleep disorders. We developed a robust deep learning model for to detect sleep-wakefulness from triaxial accelerometry and evaluated its validity across three devices and in a large adult population spanning a wide range of ages with and without sleep disorders. Methods: We collected w...",
        "published": "2025-12-01T18:43:51Z",
        "updated": "2025-12-01T18:43:51Z",
        "pdf_url": "https://arxiv.org/pdf/2512.01986v1",
        "abs_url": "https://arxiv.org/abs/2512.01986v1",
        "categories": [
          "q-bio.QM",
          "cs.LG"
        ],
        "primary_category": "q-bio.QM"
      },
      {
        "id": "2512.01984v1",
        "title": "ECO: Energy-Constrained Operator Learning for Chaotic Dynamics with Boundedness Guarantees",
        "authors": [
          "Andrea Goertzen",
          "Sunbochen Tang",
          "Navid Azizan"
        ],
        "abstract": "Chaos is a fundamental feature of many complex dynamical systems, including weather systems and fluid turbulence. These systems are inherently difficult to predict due to their extreme sensitivity to initial conditions. Many chaotic systems are dissipative and ergodic, motivating data-driven models that aim to learn invariant statistical properties over long time horizons. While recent models have shown empirical success in preserving invariant statistics, they are prone to generating unbounded ...",
        "published": "2025-12-01T18:42:02Z",
        "updated": "2025-12-01T18:42:02Z",
        "pdf_url": "https://arxiv.org/pdf/2512.01984v1",
        "abs_url": "https://arxiv.org/abs/2512.01984v1",
        "categories": [
          "eess.SY",
          "cs.LG"
        ],
        "primary_category": "eess.SY"
      },
      {
        "id": "2512.01983v1",
        "title": "Feature-Based Semantics-Aware Scheduling for Energy-Harvesting Federated Learning",
        "authors": [
          "Eunjeong Jeong",
          "Giovanni Perin",
          "Howard H. Yang",
          "Nikolaos Pappas"
        ],
        "abstract": "Federated Learning (FL) on resource-constrained edge devices faces a critical challenge: The computational energy required for training Deep Neural Networks (DNNs) often dominates communication costs. However, most existing Energy-Harvesting FL (EHFL) strategies fail to account for this reality, resulting in wasted energy due to redundant local computations. For efficient and proactive resource management, algorithms that predict local update contributions must be devised. We propose a lightweig...",
        "published": "2025-12-01T18:40:26Z",
        "updated": "2025-12-01T18:40:26Z",
        "pdf_url": "https://arxiv.org/pdf/2512.01983v1",
        "abs_url": "https://arxiv.org/abs/2512.01983v1",
        "categories": [
          "cs.LG",
          "cs.DC",
          "cs.IT",
          "cs.NI",
          "eess.SP"
        ],
        "primary_category": "cs.LG"
      },
      {
        "id": "2512.01980v1",
        "title": "Low-Rank Prehab: Preparing Neural Networks for SVD Compression",
        "authors": [
          "Haoran Qin",
          "Shansita Sharma",
          "Ali Abbasi",
          "Chayne Thrash",
          "Soheil Kolouri"
        ],
        "abstract": "Low-rank approximation methods such as singular value decomposition (SVD) and its variants (e.g., Fisher-weighted SVD, Activation SVD) have recently emerged as effective tools for neural network compression. In this setting, decomposition acts as a \"surgical\" intervention, followed by fine-tuning that serves as \"rehab\" to recover accuracy. Inspired by prehabilitation in surgery, we introduce a pre-compression fine-tuning stage, Low-Rank Prehab, that explicitly encourages low-rank structure in we...",
        "published": "2025-12-01T18:37:53Z",
        "updated": "2025-12-01T18:37:53Z",
        "pdf_url": "https://arxiv.org/pdf/2512.01980v1",
        "abs_url": "https://arxiv.org/abs/2512.01980v1",
        "categories": [
          "cs.LG"
        ],
        "primary_category": "cs.LG"
      }
    ],
    "count": 15,
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.CL"
    ],
    "fetch_date": "2025-12-02"
  },
  "metadata": {
    "source": "arXiv API",
    "query": "cat:cs.AI OR cat:cs.LG OR cat:cs.CL",
    "deduplication": {
      "total_fetched": 15,
      "new_papers": 15,
      "duplicates_filtered": 0,
      "last_fetch": "2025-12-01T09:05:27.945831"
    }
  },
  "costs": {
    "execution_time": 0.52117919921875,
    "execution_minutes": 0.008686319986979166,
    "github_actions": 6.949055989583334e-05,
    "openai": {
      "input": 0,
      "output": 0,
      "total": 0
    },
    "total": 6.949055989583334e-05,
    "token_usage": {}
  }
}